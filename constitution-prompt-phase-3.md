# Todo App - Phase 3 Constitution

**Project**: Todo AI Chatbot Application
**Phase**: Phase 3 - AI-Powered Todo Chatbot
**Version**: 1.0.0
**Ratified**: 2025-12-16
**Status**: Active
**Builds Upon**: Phase 2 Constitution (Full-Stack Web Application)

---

## CLAUDE.md Integration (READ FIRST)

**This constitution is coupled with the CLAUDE.md hierarchy. Before any work:**

1. **Read CLAUDE.md files in order:**
   - `CLAUDE.md` (root) - Master project rules and agent/skill references
   - `frontend/CLAUDE.md` - Frontend-specific guidelines
   - `backend/CLAUDE.md` - Backend-specific guidelines

2. **Use Context7 MCP BEFORE implementation:**
   - Always fetch latest library documentation via Context7
   - Required lookups: `openai-agents-sdk`, `fastmcp`, `openai-chatkit`, `framer-motion`
   - Never assume API patterns - verify first

3. **Delegate to Specialized Agents:**
   - `@ai-agent-builder` for OpenAI Agents SDK + MCP integration
   - `@mcp-server-builder` for FastMCP server development
   - `@chatbot-ui-builder` for ChatKit UI implementation
   - `@backend-api-builder` for FastAPI chat endpoints
   - `@frontend-ui-builder` for Next.js UI components
   - `@database-designer` for database schema changes

4. **Reference Skills for Setup Tasks:**
   - Check `.claude/skills/` before any initialization
   - Phase 3 skills: `openai-agents-setup`, `fastmcp-server-setup`, `chat-api-integration`, `openai-chatkit-setup`, `streaming-sse-setup`, `conversation-management`

**Coupling:** All CLAUDE.md files reference this constitution. This constitution references all CLAUDE.md files. They work together as a unified system.

---

## Project Overview

This is the constitution for the Todo App Hackathon Phase 3, where we transform the Phase 2 web application into an AI-powered chatbot interface for managing todos through natural language. This document defines the principles, standards, and practices that govern the development.

**Goal**: Build a conversational AI interface using OpenAI Agents SDK, FastMCP server, and OpenAI ChatKit that allows users to manage their tasks through natural language commands.

**Phase 3 Adds**:
- AI Agent with OpenAI Agents SDK (using Gemini model)
- MCP Server with task management tools
- ChatKit frontend for conversational interface
- Server-Sent Events (SSE) for real-time streaming
- Conversation history with database persistence

---

## Core Principles

### I. Spec-Driven Development (NON-NEGOTIABLE)

**Description**: Every feature begins with a specification. Implementation follows specification, never precedes it.

**Rules**:
- Write a complete Markdown specification for every feature before any implementation
- Specifications must include user stories, acceptance criteria, and success metrics
- No code may be written manually - all implementation must be generated by Claude Code from specifications
- Refine specifications until Claude Code generates correct output
- All specifications must be version controlled under `/specs` directory

**Rationale**: Spec-driven development ensures clear requirements, maintainable code, and alignment between intent and implementation.

---

### II. Stateless Architecture (CRITICAL FOR PHASE 3)

**Description**: The chatbot server must be completely stateless - all conversation state persists in the database.

**Rules**:
- Server holds NO in-memory conversation state
- Every request includes conversation_id to fetch history from database
- Messages stored in database immediately after generation
- Agent can be restarted without losing conversation context
- MCP tools are stateless - they operate on database state

**Rationale**: Stateless architecture enables horizontal scaling, fault tolerance, and seamless server restarts.

**Implementation Pattern**:
```
1. Receive user message with conversation_id
2. Fetch conversation history from database
3. Build message array (history + new message)
4. Store user message in database
5. Run AI agent with MCP tools
6. Store assistant response in database
7. Return response (stream or complete)
8. Server ready for next request (no state held)
```

---

### III. MCP-First Tool Design

**Description**: All task operations are exposed as MCP tools that the AI agent calls.

**Rules**:
- Use FastMCP Python SDK for MCP server implementation
- Each tool has clear input schema and return type
- Tools are thin wrappers around database operations
- Tools handle their own error responses
- Never expose raw database errors to AI agent

**MCP Server Architecture**:
- **Phase 3**: MCP Server runs as separate Python process on **port 8001**
- **Phase 4**: MCP Server becomes separate Docker container for Kubernetes deployment
- Agent connects via HTTP: `http://localhost:8001` (Phase 3) or `http://mcp-server:8001` (Phase 4)

**MCP Tools Required**:
| Tool | Purpose | Parameters |
|------|---------|------------|
| `add_task` | Create new task | user_id, title, description? |
| `list_tasks` | Get user's tasks | user_id, status? |
| `complete_task` | Mark task complete | user_id, task_id |
| `delete_task` | Remove task | user_id, task_id |
| `update_task` | Modify task | user_id, task_id, title?, description? |

**Rationale**: MCP standardizes AI-to-application communication and enables tool reuse across different AI frameworks. Separate process architecture is Kubernetes-ready for Phase 4.

---

### IV. Agent-Centric Design

**Description**: The OpenAI Agents SDK agent is the brain that interprets user intent and orchestrates tool calls.

**Rules**:
- Use OpenAI Agents SDK with Gemini model (via AsyncOpenAI wrapper)
- Agent has clear system prompt defining personality and capabilities
- Agent uses @function_tool decorators for MCP tool integration
- Implement AgentHooks and RunHooks for observability
- Use Runner.run() for synchronous execution or Runner.run_streamed() for SSE

**Agent Behavior**:
- Interpret natural language commands
- Call appropriate MCP tools
- Provide friendly, helpful responses
- Confirm actions with users
- Handle errors gracefully

**Rationale**: Centralizing AI logic in the agent ensures consistent behavior and maintainable code.

---

### V. Real-Time Streaming (SSE)

**Description**: Use Server-Sent Events for real-time response streaming from AI agent.

**Rules**:
- Implement SSE endpoint for chat responses
- Stream tokens as they're generated by the agent
- Include tool call notifications in stream
- Handle connection drops gracefully
- Support both streaming and non-streaming modes

**SSE Event Format**:
```
event: token
data: {"content": "partial response text"}

event: tool_call
data: {"tool": "add_task", "args": {"title": "..."}}

event: done
data: {"conversation_id": 123, "message_id": 456}
```

**Rationale**: Streaming provides better UX by showing responses as they're generated.

---

### VI. ChatKit UI Integration

**Description**: Use OpenAI ChatKit for the chat interface frontend.

**Rules**:
- Use OpenAI ChatKit for chatbot UI (as specified in hackathon requirements)
- Configure ChatKit with custom backend endpoint
- Implement themed components for dark mode support
- Add conversation sidebar for thread management
- Use Zustand for conversation state management
- Implement message pagination (50 messages per page, lazy load on scroll)

**UI Strategy**: 90% ChatKit, 10% Custom Fallback
- Primary: Use OpenAI ChatKit components
- Fallback: If ChatKit doesn't work, implement custom chat UI with Shadcn/ui

**Domain Allowlist Configuration (Required for Hosted ChatKit)**:
- **Local Development**: `localhost` works without domain allowlist configuration
- **Production Deployment**:
  1. Deploy frontend to get production URL (Vercel: `https://your-app.vercel.app`)
  2. Add domain to OpenAI allowlist: https://platform.openai.com/settings/organization/security/domain-allowlist
  3. Get ChatKit domain key and add to environment variables

**Environment Variable**:
```
NEXT_PUBLIC_OPENAI_DOMAIN_KEY=your-domain-key-here
```

**Rationale**: ChatKit provides production-ready chat UI components that match OpenAI's design language.

---

### VII. Conversation Persistence

**Description**: Store all conversations and messages in PostgreSQL database.

**Database Models**:

**Conversation**:
- id (int, primary key)
- user_id (string, foreign key → users.id)
- title (string, optional - auto-generated from first message)
- created_at (timestamp)
- updated_at (timestamp)

**Message**:
- id (int, primary key)
- conversation_id (int, foreign key → conversations.id)
- role (enum: 'user' | 'assistant' | 'system')
- content (text)
- tool_calls (jsonb, optional)
- created_at (timestamp)

**Rules**:
- Create new conversation if conversation_id not provided
- Auto-generate conversation title from first user message
- Store all messages immediately (don't wait for response)
- Support listing conversations by user
- Support deleting conversations

**Rationale**: Persistent conversations enable history viewing, context continuation, and user experience continuity.

---

### VIII. Security & Authentication

**Description**: Maintain Phase 2 security standards with chatbot-specific additions.

**Rules**:
- All chat endpoints require JWT authentication
- User can only access their own conversations
- MCP tools enforce user_id isolation
- Rate limit chat endpoints: **30 messages/minute per user**
- Validate all tool inputs
- Never expose internal errors to users

**Chat-Specific Security**:
- Validate conversation ownership before access
- Sanitize user messages before processing
- Limit message length: **max 4000 characters** (prevent prompt injection)
- Log all tool calls for audit trail
- Input sanitization to prevent prompt injection attacks

**Rationale**: Security is critical for AI applications to prevent misuse and data leakage.

---

### IX. Error Handling & Graceful Degradation

**Description**: Handle errors gracefully at every layer.

**Error Handling Layers**:
1. **API Layer**: Return proper HTTP status codes
2. **Agent Layer**: Catch and handle agent errors
3. **Tool Layer**: Return error messages, not exceptions
4. **Frontend Layer**: Show user-friendly error messages

**Error Response Format**:
```json
{
  "success": false,
  "error": {
    "code": "AGENT_ERROR",
    "message": "I'm sorry, I couldn't complete that action. Please try again."
  }
}
```

**Rules**:
- Never expose stack traces to users
- Provide actionable error messages
- Implement retry logic for transient failures
- Log all errors for debugging

**Rationale**: Graceful error handling maintains user trust and enables debugging.

---

### X. Progressive Enhancement from Phase 2

**Description**: Build on Phase 2 foundation without breaking existing functionality.

**Rules**:
- Preserve all Phase 2 REST API endpoints
- Add chat endpoint alongside existing APIs
- Share database models and services
- Reuse authentication middleware
- Maintain existing frontend routes

**Phase 3 Additions**:
- `/api/{user_id}/chat` - New chat endpoint
- `/app/chat` - New chat page route
- `Conversation` and `Message` models
- MCP server as separate service
- ChatKit components in frontend

**Rationale**: Progressive enhancement delivers value incrementally without regression.

---

## Technology Stack

### AI & Agent Framework
- **OpenAI Agents SDK**: 0.1.0+ - Agent orchestration
- **Gemini**: gemini-2.5-flash - LLM model (via OpenAI-compatible API)
- **FastMCP**: Latest - MCP server implementation
- **SSE**: Server-Sent Events - Real-time streaming

### Backend (Extends Phase 2)
- **Framework**: FastAPI 0.115+
- **Language**: Python 3.13+
- **ORM**: SQLModel 0.0.24+
- **Database**: Neon Serverless PostgreSQL
- **Authentication**: Better Auth (JWT tokens)
- **Package Manager**: UV

### Frontend (Extends Phase 2)
- **Framework**: Next.js 16+ (App Router)
- **Language**: TypeScript 5.0+
- **Chat UI**: @openai/chatkit-react
- **State**: Zustand 5.0+ (conversations store)
- **HTTP**: Axios with SSE support
- **Styling**: Tailwind CSS 4.0 + Shadcn/ui

### Infrastructure (Same as Phase 2)
- **Frontend Hosting**: Vercel
- **Backend Hosting**: Vercel/Railway
- **Database**: Neon Serverless PostgreSQL

---

## Claude Code Integration

### Phase 3 Specialized Agents

| Agent | Trigger | Purpose |
|-------|---------|---------|
| **AI Agent Builder** | `@ai-agent-builder` | OpenAI Agents SDK, MCP integration, Gemini config |
| **MCP Server Builder** | `@mcp-server-builder` | FastMCP server, tool definitions |
| **Chatbot UI Builder** | `@chatbot-ui-builder` | ChatKit integration, conversation UI |
| **Backend API Builder** | `@backend-api-builder` | Chat endpoints, SSE streaming |
| **Frontend UI Builder** | `@frontend-ui-builder` | Chat pages, conversation sidebar |
| **Database Designer** | `@database-designer` | Conversation/Message models, migrations |

**Agent Files**: `.claude/agents/`
- `ai-agent-builder.md` - OpenAI Agents + MCP patterns
- `mcp-server-builder.md` - FastMCP server development
- `chatbot-ui-builder.md` - ChatKit UI integration

### Phase 3 Skills Reference

| Skill | Location | Purpose |
|-------|----------|---------|
| **OpenAI Agents Setup** | `.claude/skills/openai-agents-setup/SKILL.md` | Initialize agent with Gemini |
| **FastMCP Server Setup** | `.claude/skills/fastmcp-server-setup/SKILL.md` | Create MCP server |
| **Chat API Integration** | `.claude/skills/chat-api-integration/SKILL.md` | Chat endpoint + agent |
| **OpenAI ChatKit Setup** | `.claude/skills/openai-chatkit-setup/SKILL.md` | ChatKit React components |
| **Streaming SSE Setup** | `.claude/skills/streaming-sse-setup/SKILL.md` | SSE implementation |
| **Conversation Management** | `.claude/skills/conversation-management/SKILL.md` | History UI |

### CLAUDE.md Hierarchy

1. **Root CLAUDE.md** (`./CLAUDE.md`)
   - Updated for Phase 3 agents and skills
   - Links to Phase 3 constitution

2. **Frontend CLAUDE.md** (`./frontend/CLAUDE.md`)
   - ChatKit integration patterns
   - Conversation store setup

3. **Backend CLAUDE.md** (`./backend/CLAUDE.md`)
   - Agent and MCP patterns
   - Chat endpoint patterns

---

## Development Workflow

### 1. Specification Phase (`/sp.specify`)
- Define chat feature requirements
- Document MCP tool specifications
- Define agent behavior and prompts
- Document SSE event formats

### 2. Planning Phase (`/sp.plan`)
- Design agent architecture
- Plan MCP server structure
- Design conversation database schema
- Plan ChatKit integration

### 3. Task Generation (`/sp.tasks`)
- Break down into testable tasks
- Prioritize by dependency order
- Each task independently verifiable

### 4. Implementation Phase (`/sp.implement`)
- Execute tasks in order
- Use specialized agents for each domain
- Write tests first (Red phase)
- Implement until tests pass (Green phase)

### 5. Integration Testing
- Test full conversation flow
- Verify MCP tool execution
- Test SSE streaming
- Test error handling

---

## Architecture Overview

```
┌─────────────────────────────────────────────────────────────────────┐
│                         Next.js Frontend                             │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │              ChatKit UI (Chat Interface)                     │   │
│  │  - Message list, Input, Thread sidebar                       │   │
│  │  - Zustand store for conversations                           │   │
│  │  - SSE client for streaming responses                        │   │
│  └─────────────────────────────────────────────────────────────┘   │
└───────────────────────────┬─────────────────────────────────────────┘
                            │ POST /api/{user_id}/chat (SSE)
                            ▼
┌─────────────────────────────────────────────────────────────────────┐
│                        FastAPI Backend                               │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                    Chat Endpoint                              │   │
│  │  - JWT validation                                             │   │
│  │  - Fetch conversation history from DB                         │   │
│  │  - Build message array                                        │   │
│  │  - Store user message                                         │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                            │                                         │
│                            ▼                                         │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │              OpenAI Agents SDK (Agent)                        │   │
│  │  - Gemini model via AsyncOpenAI                               │   │
│  │  - System prompt defining behavior                            │   │
│  │  - @function_tool wrappers for MCP                            │   │
│  │  - Runner.run_streamed() for SSE                              │   │
│  └─────────────────────────────────────────────────────────────┘   │
│                            │                                         │
│                            ▼                                         │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │                FastMCP Server (HTTP)                          │   │
│  │  - @mcp.tool decorators                                       │   │
│  │  - add_task, list_tasks, complete_task, delete_task          │   │
│  │  - Direct database operations via SQLModel                    │   │
│  └─────────────────────────────────────────────────────────────┘   │
└───────────────────────────┬─────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    Neon PostgreSQL Database                          │
│  - tasks (existing)                                                  │
│  - conversations (new)                                               │
│  - messages (new)                                                    │
└─────────────────────────────────────────────────────────────────────┘
```

---

## Natural Language Commands

The chatbot should understand and respond to:

| User Says | Agent Should Do |
|-----------|-----------------|
| "Add a task to buy groceries" | Call add_task with title "Buy groceries" |
| "Show me all my tasks" | Call list_tasks with status "all" |
| "What's pending?" | Call list_tasks with status "pending" |
| "Mark task 3 as complete" | Call complete_task with task_id 3 |
| "Delete the meeting task" | Call list_tasks first, then delete_task |
| "Change task 1 to 'Call mom tonight'" | Call update_task with new title |
| "I need to remember to pay bills" | Call add_task with title "Pay bills" |
| "What have I completed?" | Call list_tasks with status "completed" |

---

## Code Quality Standards

### Agent Code (Python)
```python
# GOOD: Clear agent definition with typed tools
from agents import Agent, Runner, function_tool
from agents.extensions.models.litellm import LitellmModel

model = LitellmModel(model="gemini/gemini-2.5-flash", api_key=GEMINI_API_KEY)

@function_tool
async def add_task(user_id: str, title: str, description: str = "") -> dict:
    """Add a new task for the user."""
    result = await mcp_client.call_tool("add_task", {
        "user_id": user_id,
        "title": title,
        "description": description
    })
    return result

agent = Agent(
    name="TodoBot",
    instructions="You are a helpful todo assistant...",
    model=model,
    tools=[add_task, list_tasks, complete_task, delete_task, update_task]
)
```

### MCP Server Code (Python)
```python
# GOOD: Clean MCP tool definition
from fastmcp import FastMCP
from sqlmodel import Session, select

mcp = FastMCP("Todo MCP Server")

@mcp.tool()
async def add_task(user_id: str, title: str, description: str = "") -> dict:
    """Create a new task for the user."""
    async with get_session() as session:
        task = Task(user_id=user_id, title=title, description=description)
        session.add(task)
        await session.commit()
        await session.refresh(task)
        return {"task_id": task.id, "status": "created", "title": task.title}
```

### ChatKit Frontend (TypeScript)
```typescript
// GOOD: Chat interface with Zustand state management
// Note: Verify exact ChatKit package import from OpenAI documentation
'use client';

import { useConversationStore } from '@/stores/conversation-store';

export function ChatInterface() {
  const { currentConversation, messages, sendMessage, isStreaming } = useConversationStore();

  const handleSendMessage = async (content: string) => {
    await sendMessage({
      conversationId: currentConversation?.id,
      message: content,
    });
  };

  return (
    <div className="flex flex-col h-full">
      {/* Message list */}
      <div className="flex-1 overflow-y-auto">
        {messages.map((msg) => (
          <MessageBubble key={msg.id} message={msg} />
        ))}
      </div>

      {/* Input area - integrate with ChatKit components */}
      <ChatInput onSend={handleSendMessage} disabled={isStreaming} />
    </div>
  );
}
```

**ChatKit Integration Notes**:
- Refer to https://platform.openai.com/docs/guides/chatkit for latest API
- Use Context7 MCP to fetch current ChatKit documentation before implementation
- ChatKit handles streaming, message formatting, and UI state

---

## Environment Variables (Phase 3 Additions)

```env
# AI/Agent Configuration
GEMINI_API_KEY=your_gemini_api_key
GEMINI_MODEL=gemini-2.5-flash

# MCP Server
MCP_SERVER_URL=http://localhost:8001/mcp
MCP_SERVER_PORT=8001

# ChatKit (Frontend - for production deployment)
NEXT_PUBLIC_OPENAI_DOMAIN_KEY=your-domain-key-here

# Existing Phase 2 variables remain unchanged
DATABASE_URL=postgresql+asyncpg://...
BETTER_AUTH_SECRET=...
CORS_ORIGINS=http://localhost:3000
```

---

## Security Checklist (Phase 3 Additions)

- [ ] Chat endpoints validate JWT tokens
- [ ] User can only access their own conversations
- [ ] MCP tools validate user_id ownership
- [ ] Message content length is limited
- [ ] Rate limiting on chat endpoints
- [ ] Tool calls are logged for audit
- [ ] No sensitive data in agent responses
- [ ] SSE connections properly authenticated

---

## Testing Strategy

### Unit Tests
- Agent tool functions
- MCP tool handlers
- Conversation service methods

### Integration Tests
- Full chat flow (message → agent → tools → response)
- Conversation CRUD operations
- SSE streaming functionality

### E2E Tests
- User journey: login → chat → create task via chat → verify task
- Conversation history persistence
- Error handling scenarios

**Test Coverage Goals**:
- Backend: 80%
- Frontend: 70%
- Critical paths: 100%

---

## Governance

### Constitution Authority
- This constitution supersedes all other practices for Phase 3
- Phase 2 constitution remains valid for non-chat features
- All code reviews must verify compliance
- Violations must be justified and documented

### Change Management
- Constitution changes require new version number
- Document rationale for all amendments
- Update CLAUDE.md to reflect changes

---

## References

- [Hackathon II Documentation](./Hackathon%20II%20-%20Todo%20Spec-Driven%20Development.md)
- [Phase 2 Constitution](./prompts/constitution-prompt-phase-2.md)
- [OpenAI Agents SDK Documentation](https://openai.github.io/openai-agents-python/)
- [FastMCP Documentation](https://github.com/jlowin/fastmcp)
- [OpenAI ChatKit Documentation](https://platform.openai.com/docs/guides/chatkit)
- [Server-Sent Events MDN](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)

---

**Version**: 1.0.0 | **Ratified**: 2025-12-16 | **Last Amended**: 2025-12-16
